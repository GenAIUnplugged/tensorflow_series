{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GenAIUnplugged/tensorflow_series/blob/main/cifar_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWNbuvyUYryS",
        "outputId": "8e8df5cd-de1e-40ca-ae54-8c8dd3b7ee73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPubett9Z45Z",
        "outputId": "1b08890a-0813-4b06-f9cb-f830fc457d40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xYApyQpZRvz"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "# Load the CIFAR-10 dataset\n",
        "ds = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    shuffle_files=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Siex1e14ZpLt",
        "outputId": "ea5e03dc-777a-4a74-b5ee-8c712e339517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([<_PrefetchDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
              "  <_PrefetchDataset element_spec=(TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>],\n",
              " tfds.core.DatasetInfo(\n",
              "     name='cifar10',\n",
              "     full_name='cifar10/3.0.2',\n",
              "     description=\"\"\"\n",
              "     The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
              "     \"\"\",\n",
              "     homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
              "     data_dir='/root/tensorflow_datasets/cifar10/3.0.2',\n",
              "     file_format=tfrecord,\n",
              "     download_size=162.17 MiB,\n",
              "     dataset_size=132.40 MiB,\n",
              "     features=FeaturesDict({\n",
              "         'id': Text(shape=(), dtype=string),\n",
              "         'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
              "         'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "     }),\n",
              "     supervised_keys=('image', 'label'),\n",
              "     disable_shuffling=False,\n",
              "     nondeterministic_order=False,\n",
              "     splits={\n",
              "         'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
              "         'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
              "     },\n",
              "     citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
              "         author = {Alex Krizhevsky},\n",
              "         title = {Learning multiple layers of features from tiny images},\n",
              "         institution = {},\n",
              "         year = {2009}\n",
              "     }\"\"\",\n",
              " ))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnWOyIa-a3Dz"
      },
      "outputs": [],
      "source": [
        "(ds_train,ds_test),ds_info = ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "JuN3pcX6bDfl",
        "outputId": "7937c1ce-99b9-4172-bbbc-f01b920c13b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 31);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ds_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ondq3_nXbEwj",
        "outputId": "73b350fb-d18d-4113-c060-652bf62865eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='cifar10',\n",
              "    full_name='cifar10/3.0.2',\n",
              "    description=\"\"\"\n",
              "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
              "    \"\"\",\n",
              "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
              "    data_dir='/root/tensorflow_datasets/cifar10/3.0.2',\n",
              "    file_format=tfrecord,\n",
              "    download_size=162.17 MiB,\n",
              "    dataset_size=132.40 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'id': Text(shape=(), dtype=string),\n",
              "        'image': Image(shape=(32, 32, 3), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    nondeterministic_order=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
              "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
              "    },\n",
              "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
              "        author = {Alex Krizhevsky},\n",
              "        title = {Learning multiple layers of features from tiny images},\n",
              "        institution = {},\n",
              "        year = {2009}\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKQj5Ru7bOK9"
      },
      "outputs": [],
      "source": [
        "def preprocess(image, label):\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  label = tf.one_hot(label, depth=10)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNWOFZjpcZUa"
      },
      "outputs": [],
      "source": [
        "ds_train = ds_train.map(preprocess)\n",
        "ds_test = ds_test.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa47n8ubc23M"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "history = model.fit(ds_train.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE),\n",
        "                    epochs=10,\n",
        "                    validation_data=ds_test.batch(BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFOD0XqLccOY",
        "outputId": "47c53f72-9034-41b1-cb56-99d0384d19fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax') # Output layer with 10 units for 10 classes\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f1bCQDMcokH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNjKJmUGdFG6",
        "outputId": "aa85fec0-be7f-4712-a94e-f8be42d15553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 55ms/step - accuracy: 0.3552 - loss: 1.7433 - val_accuracy: 0.5351 - val_loss: 1.3041\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 46ms/step - accuracy: 0.5677 - loss: 1.2184 - val_accuracy: 0.5937 - val_loss: 1.1527\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 44ms/step - accuracy: 0.6297 - loss: 1.0552 - val_accuracy: 0.6333 - val_loss: 1.0566\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.6666 - loss: 0.9479 - val_accuracy: 0.6603 - val_loss: 0.9806\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 45ms/step - accuracy: 0.6952 - loss: 0.8684 - val_accuracy: 0.6797 - val_loss: 0.9374\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.7173 - loss: 0.8073 - val_accuracy: 0.6871 - val_loss: 0.9129\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 45ms/step - accuracy: 0.7348 - loss: 0.7570 - val_accuracy: 0.6934 - val_loss: 0.9018\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 44ms/step - accuracy: 0.7497 - loss: 0.7136 - val_accuracy: 0.6974 - val_loss: 0.9102\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 45ms/step - accuracy: 0.7674 - loss: 0.6698 - val_accuracy: 0.6993 - val_loss: 0.9325\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 44ms/step - accuracy: 0.7808 - loss: 0.6292 - val_accuracy: 0.6966 - val_loss: 0.9715\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "history = model.fit(ds_train.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE),\n",
        "                    epochs=10,\n",
        "                    validation_data=ds_test.batch(BATCH_SIZE))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOMZHS/KkMHRUf4alrGN2Td",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}