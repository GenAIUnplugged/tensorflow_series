{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsdHlSICcFSgon1BpTKN7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GenAIUnplugged/tensorflow_series/blob/main/Transfer_Learning_Tensorflow_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khf2Z3RKUxBq"
      },
      "outputs": [],
      "source": [
        "# flowers_transfer_learning.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Load the Flowers dataset\n",
        "(train_ds, val_ds), ds_info = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "# Preprocessing function\n",
        "def format_example(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Prepare datasets\n",
        "train_ds = train_ds.map(format_example).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(format_example).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Load MobileNetV2 base model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
        "\n",
        "# Optional fine-tuning\n",
        "base_model.trainable = True\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "history_fine = model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
        "\n",
        "# Save the model\n",
        "model.save('flowers_mobilenetv2.h5')\n",
        "\n",
        "# Plot training history\n",
        "def plot_history(histories, titles):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for i, (history, title) in enumerate(zip(histories, titles)):\n",
        "        plt.subplot(1, 2, i+1)\n",
        "        plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "        plt.title(f'{title} Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history([history, history_fine], ['Initial', 'Fine-tuned'])\n"
      ]
    }
  ]
}